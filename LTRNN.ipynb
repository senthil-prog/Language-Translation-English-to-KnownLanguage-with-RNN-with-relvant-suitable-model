{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsycKei94H9d",
        "outputId": "81939243-7470-4f75-e5cf-4ab1c2e14864"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Folder where your data is stored\n",
        "data_folder = \"/content/drive/MyDrive/data\"\n",
        "os.makedirs(data_folder, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio sentencepiece\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pa20Tsvr4L2T",
        "outputId": "1520f2c3-fc17-42c0-ab20-d298530e6eff"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder = \"/content/drive/MyDrive/data\"\n",
        "\n",
        "# English sentences\n",
        "with open(f\"{data_folder}/en.train.fixed.txt\", encoding=\"utf-8\") as f:\n",
        "    english_sentences = f.read().splitlines()\n",
        "\n",
        "# Kannada sentences\n",
        "with open(f\"{data_folder}/kn.train.fixed.txt\", encoding=\"utf-8\") as f:\n",
        "    kannada_sentences = f.read().splitlines()\n",
        "\n",
        "print(\"Loaded dataset:\")\n",
        "print(\"Total sentences:\", len(english_sentences))\n",
        "print(\"Sample English:\", english_sentences[0])\n",
        "print(\"Sample Kannada:\", kannada_sentences[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWTuZHUt4agM",
        "outputId": "ea490889-30c4-4b2b-a275-d6ea2eb6cce1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded dataset:\n",
            "Total sentences: 2432\n",
            "Sample English: Birth: 15-09-1931 Uru: Managuli village of Basavan Bavewadi Taluk in Bijapur District. Education: BA Honors degree. 25-04-1955: Gives Spiritual Repentance. \n",
            "Sample Kannada: ಜನನ : 15-09-1931 ಉರು: ಬಿಜಾಪುರ ಜಿಲ್ಲೆಯ ಬಸವನ ಬಾಗೇವಾಡಿ ತಾಲ್ಲೋಕಿನ ಮನುಗೂಳಿ ಗ್ರಾಮ. ವಿದ್ಯಾಭ್ಯಾಸ: ಬಿ.ಎ. ಆನರ್್ಸ ಪದವಿ. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "import os\n",
        "\n",
        "data_folder = \"/content/drive/MyDrive/data\"\n",
        "\n",
        "# Make sure dataset is loaded first\n",
        "with open(f\"{data_folder}/en.train.fixed.txt\", encoding=\"utf-8\") as f:\n",
        "    english_sentences = f.read().splitlines()\n",
        "\n",
        "with open(f\"{data_folder}/kn.train.fixed.txt\", encoding=\"utf-8\") as f:\n",
        "    kannada_sentences = f.read().splitlines()\n",
        "\n",
        "# Save corpus files for tokenizer training\n",
        "with open(f\"{data_folder}/corpus.en\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(english_sentences))\n",
        "\n",
        "with open(f\"{data_folder}/corpus.kn\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(kannada_sentences))\n",
        "\n",
        "# Train tokenizers (only once; if already trained, you can skip)\n",
        "spm.SentencePieceTrainer.train(input=f\"{data_folder}/corpus.en\", model_prefix=f\"{data_folder}/spm_en\", vocab_size=8000)\n",
        "spm.SentencePieceTrainer.train(input=f\"{data_folder}/corpus.kn\", model_prefix=f\"{data_folder}/spm_kn\", vocab_size=8000)\n",
        "\n",
        "# Load tokenizers\n",
        "sp_en = spm.SentencePieceProcessor(model_file=f\"{data_folder}/spm_en.model\")\n",
        "sp_kn = spm.SentencePieceProcessor(model_file=f\"{data_folder}/spm_kn.model\")\n",
        "\n",
        "print(\"Tokenizers ready!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEIs96uG4c9P",
        "outputId": "33c6559a-45f1-4944-adb0-540878c06251"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizers ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers=1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, hid_dim, n_layers, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hid_dim*2, hid_dim)\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.embedding(src)\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "        # Combine bidirectional hidden for decoder\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))).unsqueeze(0)\n",
        "        return outputs, hidden\n"
      ],
      "metadata": {
        "id": "Bf8D0Td64gRf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LuongAttention(nn.Module):\n",
        "    def __init__(self, hid_dim):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Linear(hid_dim*3, hid_dim)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        # hidden: [1, batch, hid_dim]\n",
        "        # encoder_outputs: [batch, seq_len, hid_dim*2]\n",
        "        batch_size = encoder_outputs.shape[0]\n",
        "        seq_len = encoder_outputs.shape[1]\n",
        "\n",
        "        hidden_expanded = hidden.permute(1,0,2).repeat(1, seq_len, 1)  # [batch, seq_len, hid_dim]\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden_expanded, encoder_outputs), dim=2)))  # [batch, seq_len, hid_dim]\n",
        "        attention = torch.sum(energy, dim=2)  # [batch, seq_len]\n",
        "        return torch.softmax(attention, dim=1)\n"
      ],
      "metadata": {
        "id": "hXtlo3Iz4kX0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, attention, n_layers=1):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.attention = attention\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim + hid_dim*2, hid_dim, n_layers, batch_first=True)\n",
        "        self.fc_out = nn.Linear(hid_dim + hid_dim*2 + emb_dim, output_dim)  # Correct dimensions\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        input = input.unsqueeze(1)  # [batch,1]\n",
        "        embedded = self.embedding(input)  # [batch,1,emb_dim]\n",
        "\n",
        "        # Attention\n",
        "        a = self.attention(hidden, encoder_outputs).unsqueeze(1)  # [batch,1,seq_len]\n",
        "        weighted = torch.bmm(a, encoder_outputs)  # [batch,1,hid_dim*2]\n",
        "\n",
        "        rnn_input = torch.cat((embedded, weighted), dim=2)  # [batch,1, emb+hid*2]\n",
        "        output, hidden = self.rnn(rnn_input, hidden)\n",
        "\n",
        "        output_cat = torch.cat((output.squeeze(1), weighted.squeeze(1), embedded.squeeze(1)), dim=1)  # [batch, hid+hid*2+emb]\n",
        "        prediction = self.fc_out(output_cat)\n",
        "        return prediction, hidden\n"
      ],
      "metadata": {
        "id": "ZwsTDJsP4nvS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        batch_size, trg_len = trg.size(0), trg.size(1)\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
        "\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "        input = trg[:,0]\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            output, hidden = self.decoder(input, hidden, encoder_outputs)\n",
        "            outputs[:,t] = output\n",
        "            top1 = output.argmax(1)\n",
        "            input = trg[:,t] if torch.rand(1).item() < teacher_forcing_ratio else top1\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "LED6EpLY4p0e"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.utils.rnn as rnn_utils\n",
        "\n",
        "# Custom dataset class\n",
        "class ParallelDataset(Dataset):\n",
        "    def __init__(self, src_sentences, trg_sentences, sp_src, sp_trg, max_len=50):\n",
        "        self.src_sentences = src_sentences\n",
        "        self.trg_sentences = trg_sentences\n",
        "        self.sp_src = sp_src\n",
        "        self.sp_trg = sp_trg\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src = [self.sp_src.bos_id()] + self.sp_src.EncodeAsIds(self.src_sentences[idx]) + [self.sp_src.eos_id()]\n",
        "        trg = [self.sp_trg.bos_id()] + self.sp_trg.EncodeAsIds(self.trg_sentences[idx]) + [self.sp_trg.eos_id()]\n",
        "        return torch.tensor(src[:self.max_len]), torch.tensor(trg[:self.max_len])\n",
        "\n",
        "# Initialize dataset & dataloader\n",
        "dataset = ParallelDataset(english_sentences, kannada_sentences, sp_en, sp_kn)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=lambda batch: batch)\n",
        "\n",
        "print(\"✅ DataLoader is ready!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMOP5SkyoLKq",
        "outputId": "f9dedab8-6bd1-4bd0-a970-340b6e01ec9d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ DataLoader is ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Attention\n",
        "attn = LuongAttention(HID_DIM)\n",
        "\n",
        "# Encoder & Decoder\n",
        "enc = Encoder(INPUT_DIM, EMB_DIM, HID_DIM).to(DEVICE)\n",
        "dec = Decoder(OUTPUT_DIM, EMB_DIM, HID_DIM, attn).to(DEVICE)\n",
        "\n",
        "# Seq2Seq\n",
        "model = Seq2Seq(enc, dec, DEVICE).to(DEVICE)\n",
        "\n",
        "# Optimizer & Loss\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)  # ignore padding\n"
      ],
      "metadata": {
        "id": "Z8k76n2LoNEt"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "INPUT_DIM = len(sp_en)    # English vocab size\n",
        "OUTPUT_DIM = len(sp_kn)   # Kannada vocab size\n",
        "HID_DIM = 256\n",
        "EMB_DIM = 256\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 32\n"
      ],
      "metadata": {
        "id": "LtpFnOdw4sU4"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.utils.rnn as rnn_utils\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        src, trg = zip(*batch)\n",
        "        src = rnn_utils.pad_sequence(src, batch_first=True).to(DEVICE)\n",
        "        trg = rnn_utils.pad_sequence(trg, batch_first=True).to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg)  # [batch, trg_len, vocab_size]\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[:,1:,:].reshape(-1, output_dim)  # ignore <sos>\n",
        "        trg = trg[:,1:].reshape(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {epoch_loss/len(dataloader):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyhsinPO6U0n",
        "outputId": "b974439d-32ff-447c-f15f-d116b6671505"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 7.0969\n",
            "Epoch 2/20, Loss: 5.9858\n",
            "Epoch 3/20, Loss: 5.4051\n",
            "Epoch 4/20, Loss: 4.8945\n",
            "Epoch 5/20, Loss: 4.3425\n",
            "Epoch 6/20, Loss: 3.8701\n",
            "Epoch 7/20, Loss: 3.4001\n",
            "Epoch 8/20, Loss: 3.0456\n",
            "Epoch 9/20, Loss: 2.7187\n",
            "Epoch 10/20, Loss: 2.4415\n",
            "Epoch 11/20, Loss: 2.2458\n",
            "Epoch 12/20, Loss: 2.0095\n",
            "Epoch 13/20, Loss: 1.8493\n",
            "Epoch 14/20, Loss: 1.6637\n",
            "Epoch 15/20, Loss: 1.5116\n",
            "Epoch 16/20, Loss: 1.3641\n",
            "Epoch 17/20, Loss: 1.1976\n",
            "Epoch 18/20, Loss: 1.1083\n",
            "Epoch 19/20, Loss: 0.9724\n",
            "Epoch 20/20, Loss: 0.8254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(sentence, model, sp_en, sp_kn, max_len=50):\n",
        "    model.eval()\n",
        "    tokens = [1] + sp_en.encode(sentence, out_type=int) + [2]\n",
        "    src_tensor = torch.tensor(tokens).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "    encoder_outputs, hidden = model.encoder(src_tensor)\n",
        "    input_tok = torch.tensor([1]).to(DEVICE)  # <sos>\n",
        "    outputs = []\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        output, hidden = model.decoder(input_tok, hidden, encoder_outputs)\n",
        "        pred_token = output.argmax(1).item()\n",
        "        if pred_token == 2:  # <eos>\n",
        "            break\n",
        "        outputs.append(pred_token)\n",
        "        input_tok = torch.tensor([pred_token]).to(DEVICE)\n",
        "\n",
        "    return sp_kn.decode(outputs)\n"
      ],
      "metadata": {
        "id": "PFnP_YMO6WUi"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    english_text = input(\"Enter English sentence (or 'quit' to stop): \")\n",
        "    if english_text.lower() == \"quit\":\n",
        "        break\n",
        "    kannada_translation = translate_sentence(english_text, model, sp_en, sp_kn)\n",
        "    print(\"Kannada:\", kannada_translation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQNTM7FkMbmv",
        "outputId": "0a4d9721-2009-4b31-8137-8683afc765cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter English sentence (or 'quit' to stop): Birth: 15-09-1931 Uru: Managuli village of Basavan Bavewadi Taluk in Bijapur District. Education: BA Honors degree. 25-04-1955: Gives Spiritual Repentance.\n",
            "Kannada: ಜನನ : ಬಿ ಜನನ ಜಿಲ್ಲೆಯ ಬಸವನ ಬಾಗೇವಾಡಿ ತಾಲ್ಲೋಕಿನ ಮನುಗೂಳಿ ಗ್ರಾಮ. ವಿದ್ಯಾಭ್ಯಾಸ: ಬಿಎ. ಆನರ್್ಸ ಪದವಿರ್.ಸ ಪದವಿ. ಪದವಿರ್ ಪ್ಯಾರ್ಸ ಪದವಿ. ಪದವಿ.ಸ ಪದವಿ.ಸ ಪದವಿ. ಪದವಿ.ಸ ಪದವಿ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zQRKV3tEOVf-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}